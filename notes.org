* Chapter 1
** Beta normal form is when you cannot beta reduce (apply lambdas to arguments) the terms any further. 
** Lambda calculus is a formal system for expressing programs in terms of abstraction and application.
* Chapter 2
   * /Reducing/ an expression means evaluating the terms until you’re left with a value
   * Expression is in canonical or /normal form/ when it reaches the number 6 because the value 6 has no remaining reducible expressions. 
Haskell’s nonstrict evaluation means not everything will get reduced to its irreducible form immediately, so this:
 ~(\f -> (1, 2 + f)) 2~
reduces to the following in WHNF:
 ~(1, 2 + 2)~
   * /let/ introduces an expression, so it can be used wherever you can have an expression, but /where/ is a declaration and is bound to a surrounding syntactic construct.
   *  In Haskell, an /expression/ is a well-structured combination of constants, variables, and functions.
* Chapter 4
    * /Data declarations/ are how datatypes are defined.
    * /The type constructor/ is the name of the type and is capitalized.
    * Data constructors are the values that inhabit the type they are defined in.
    * Example of data desclaration:
   #+BEGIN_SRC haskell
   data Bool = False | True
   --   [1]     [2] [3] [4]
   #+END_SRC 
   1. Type constructor for datatype Bool. This is the name of the type and shows up in type signatures.
   2. Data constructor for the value False.
   3. Pipe | indicates a sum type or logical disjunction: “or.” So, a Bool value is True or False.
   4. Data constructor for the value True.
** Numeric types:
   1. Integral Numbers:
      1. Int
      2. Integer
   2. Fractional
      1. Float
      2. Double
      3. Rational
** Typeclass
   * /Typeclass/ is a set of operations defined with respect to a polymorphic type.
   When a type is an instance of a typeclass, values of that type can be used in the standard operations defined for that typeclass. In Haskell, typeclasses are unique pairings of class and concrete instance. This means that if a given type a has an instance of Eq, it has only one instance of Eq.
* Chapter 5
    * In Haskell, you cannot create untyped data, so except for a sprinkling of syntactic sugar for things like numbers or functions, everything originates in a data constructor from some definition of a type.
    * The arrow, ~(->)~, is the *type constructor* for functions in Haskell.
#+BEGIN_SRC haskell
(Ord a, Num a) => a -> a -> Ordering
#+END_SRC
    Here, the constraints look like a tuple but they don’t add another function argument that you must provide, and they don’t appear as a tuple at the value or term level. Nothing to the left of the type-class arrow, =>, shows up at term level. The tuple of constraints does represent a product, or conjunction, of constraints.
    Compare:
   #+BEGIN_SRC haskell
       Prelude> :info (->)
       data (->) a b

     -- If you compare this to the type constructor for the two-tuple, you
     -- see the similarity:
       Prelude> :info (,)
       data (,) a b = (,) a b
   #+END_SRC
   Unlike the tuple constructor, though, the function type has no data constructors. The value that shows up at term level is the function. 
   * /Functions are values./
   The parameterization suggests that we will apply the function to some argument that will be bound to the first parameter, with the second parameter, b, representing the return or result type.
** Type signature constraints
   * Example - ~(Ord a, Num a) => a -> a -> Ordering~
   Here, the constraints look like a tuple but they don’t add another function argument that you must provide, and they don’t appear as a tuple at the value or term level. Nothing to the left of the type-class arrow, =>, shows up at term level. The tuple of constraints does represent a product, or conjunction, of constraints.
    * The way the ~(->)~ type constructor for functions works means ~a -> a -> a~ represents successive function applications, each taking one argument and returning one result. The difference is that the function at the outermost layer is actually returning another function that accepts the next argument. This is called currying.
    * Explicit parenthesization, as when an input parameter is itself a function (such as in map, above), may be used to indicate order of evaluation, but the implicit associativity of the function type does not mean the inner or final set of parentheses, i.e., the result type, evaluates first. Application is evaluation; in other words, the only way to evaluate anything is by applying functions, and function applica- tion is left associative. So, the leftmost, or outermost, arguments will be evaluated first, assuming anything gets evaluated (since Haskell is nonstrict, you can’t assume that anything will be evaluated, but this will be more clear later).
Also - https://stackoverflow.com/questions/36143423/right-associativity-in-type-signatures-of-functions
** Partial Application
   * ~(2^)~ (left section) is equivalent to ~(^) 2~ , or more verbosely ~\x -> 2 ^ x~
   * ~(^2)~ (right section) is equivalent to ~flip (^) 2~ , or more verbosely ~\x -> x ^ 2~
   * More - https://wiki.haskell.org/Section_of_an_infix_operator
Partial application is common enough in Haskell that, over time, you’ll develop an intuition for it. The sectioning syntax exists to allow some freedom in which argument of a binary operator you apply the function to.
** Polymorphism
   * Type signatures may have three kinds of types: concrete, constrained polymorphic, or parametrically polymorphic.
   * /Constrained/ = Ad-hoc polymorphyc. Ad-hoc polymorphism in Haskell is implemented with typeclasses.
   * /Typeclass constraints/ limit the set of potential types (and, thus, potential values) while also passing along the common functions that can be used with those values.
   * /Parametricity/ means that the behavior of a function with respect to the types of its (parametrically polymorphic) arguments is uniform.
   Parametricity is the property we get from having parametric polymorphism.
** Type inference
   * Haskell’s type inference is built on an extended version of the /Damas-Hindley-Milner/ type system.

* Chapter 6
** Haskell and purity (Show typeclass section)
   * /Side effect/ -- a potentially observable result apart from the value the expression evaluates to.
   Haskell manages effects by separating effectful computations from pure computations in ways that preserve the predictability and safety of function evaluation. Importantly, effect-bearing computations themselves become more composable and easier to reason about. The benefits of explicit effects include the fact that it makes it relatively easy to reason about and predict the results of our functions.
   * ~main~ has IO () type because ~main` /only/ produces side effects.
   * /IO/ is the type for values whose evaluation bears the possibility of causing side effects, such as printing text, reading text input from the user, reading or writing files, or connecting to remote computers.
** Instances are dispatched by type
* Chapter 7
** Interesting point about lambda functions
   > We won’t go into a lot of detail about this yet, but named entities and anonymous entities evaluate a bit differently in Haskell, and that can be one reason to use an anonymous function in some cases.
* Chapter 8
** Y-combinator
   * We use a combinator – known as the /Y combinator/ or fixed-point combinator – to write recursive functions in the lambda calculus. Haskell has native recursion ability based on the same principle as the Y combinator.
   * Also - http://mvanier.livejournal.com/2897.html
** Bottom
   * ⊥ or bottom is a term used in Haskell to refer to computations that do not successfully result in a value. The two main varieties of bottom are computations that failed with an error or those that failed to terminate.
* Chapter 9
** List's sintactic sugar
   * When we talk about lists, we often talk about them in terms of /cons cells/ and /spines/. 
     ** The cons cells are the list datatype’s second data constructor, a : [a], the result of recursively prepending a value to “more list.” The cons cell is a conceptual space that values may inhabit.
     ** The spine is the connective structure that holds the cons cells together and in place. As we will soon see, this structure nests the cons cells rather than ordering them in a right-to-left row. Because different functions may treat the spine and the cons cells differently, it is important to understand this underlying structure.
** Spines and nonstrict evaluation
   * When we talk about data structures in Haskell, particularly lists, sequences, and trees, we talk about them having a /spine/. This is the connective structure that ties the collection of values together.
   The problem with the ~1 : (2 : (3 : []))~ representation we used earlier is that it makes it seem like the value 1 exists “before” the cons (:) cell that contains it, but actually, the cons cells contain the values. Because of this and the way nonstrict evaluation works, you can evaluate cons cells independently of what they contain. It is possible to evaluate just the spine of the list without evaluating individual values. It is also possible to evaluate only part of the spine of a list and not the rest of it.
   Evaluation of the list in this representation proceeds /down/ the spine. Constructing the list when that is necessary, however, proceeds /up/ the spine.
   Because Haskell’s evaluation is nonstrict, the list isn’t constructed until it’s consumed — indeed, nothing is evaluated until it must be. Until it’s consumed or you force strictness in some way, there are a series of placeholders as a blueprint of the list that can be constructed when it’s needed.
   #+BEGIN_SRC 
  :                :  <------|
 / \              / \        |
1   :            _   :  <----|  -----  This is the "spine"
   / \     -->      / \      |
  2   :            _   :  <--|
     / \              / \
     3 []             _ []
   #+END_SRC
   * A special command in GHCi called ~sprint~ to print variables and see what has been evaluated already, with the underscore representing expressions that haven’t been evaluated yet.
   * GHC Haskell has some opportunistic optimizations which introduce strictness to make code faster when it won’t change how your code evaluates.
   * Polymorphism means values like Num a => a are really waiting for a sort of argument which will make it concrete. Due to it sprint may behave confusing.
   * Example of list evaluation:
#+BEGIN_SRC 
Prelude> :sprint blah
blah = _
-- The blah = _ indicates that blah is totally unevaluated. Next we’ll take one value from blah and then evaluate it by forcing GHCi to print the expression:
Prelude> take 1 blah
"a"
Prelude> :sprint blah
blah = 'a' : _
#+END_SRC
   * Spines are evaluated independently of values
   * *WHNF* (‘Weak head normal form’) means the expression is only evaluated as far as is necessary to reach a data constructor.
   Weak head normal form (WHNF) is a larger set and contains both the possibility that the expression is:
     1. Fully evaluated (*normal form*)
     2. Has been evaluated to the point of arriving at a *data constructor* 
     3. *Lambda* awaiting an argument.

   * /Weak Head/ is an expression which is evaluated up to /at least/ the first data constructor.
   * /Normal form/ exceeds that by requiring that all sub-expressions be fully evaluated.
   * Functions that are spine strict can force complete evaluation of the spine of the list even if they don’t force evaluation of each value.
     * Pattern matching is strict by default, so pattern matching on cons cells can mean forcing spine strictness if your function doesn’t stop recursing the list. It can evaluate the spine only or the spine as well as the values that inhabit each cons cell, depending on context.
   * /Lazy in the spine, strict in the leaves/
   We can have lazily evaluated code (e.g., map) wrapped around a strict core (e.g., +). In fact, we can choose to apply laziness and strictness in how we evaluate the spine or the leaves independently.

** Defenitions
   * /Cons cell/ is a data constructor and a product of the types a and [a] as defined in the list datatype.
   Because it references the list type constructor itself in the second argument, it allows for nesting of multiple cons cells, possibly indefinitely with the use of recursive functions, for representing an indefinite number of values in series:
#+BEGIN_SRC 
data [] a = [] | a : [a]
                   ^ cons operator
-- Defining it ourselves
data List a = Nil | Cons a (List a)
-- Creating a list using our list type
Cons 1 (Cons 2 (Cons 3 Nil))
#+END_SRC
   Here (Cons 1 ...), (Cons 2 ...) and (Cons 3 Nil) are all individual cons cells in the list [1, 2, 3].
   * The spine is a way to refer to the structure that glues a collection of values together. In the list datatype it is formed by the recursive nesting of cons cells. The spine is, in essence, the structure of collection that isn’t the values contained therein. Often spine will be used in reference to lists, but it applies with tree data structures as well

* Chapter 10
**  Evaluation of fold functions
   * Folding is two stage process, and include /traversal/ and /folding/.
    * Traversal is the stage in which the fold recurses over the spine. Traversing the rest of the spine /doesn’t occur/ unless the function asks for the results of having folded the rest of the list. 
    * Folding refers to the evaluation or reduction of the folding function applied to the values. Given this two-stage process and non-strict evaluation, if ~f~ doesn’t evaluate its second argument (rest of the fold), no more of ~t~he spine will be forced. One of the consequences of this is that foldr can avoid evaluating not just some or all of the values in the list, but some or all of the list’s spine as well! For this reason, foldr can be used with lists that are potentially infinite.
** Types of Fold functions
*** Foldr
    * Definition:
#+BEGIN_SRC haskell
foldr :: (a -> b -> b) -> b -> [a] -> b
foldr f z [] = z
foldr f z (x:xs) = f x (foldr f z xs)
#+END_SRC
    * Associates to right, so:
#+BEGIN_SRC haskell
foldr (+) 0 [1, 2, 3]
-- expands to
1 + (2 + (3 + 0))
#+END_SRC
    * Traverses from head to tail, reduces backward
    * Works well with infinite lists:
#+BEGIN_SRC 
Prelude> myAny even [1..] -- myAny is defined through foldr
True
#+END_SRC

*** Foldl
    * Definition:
#+BEGIN_SRC haskell
foldl :: (b -> a -> b) -> b -> [a] -> b
foldl f acc [] = acc
foldl f acc (x:xs) = foldl f (f acc x) xs
#+END_SRC
    *  Associates to left, so:
#+BEGIN_SRC haskell
foldl (+) 0 (1 : 2 : 3 : [])
-- expands to
((0 + 1) + 2) + 3
#+END_SRC
    * Traverses and reduces in the same direction - from head to tail.
